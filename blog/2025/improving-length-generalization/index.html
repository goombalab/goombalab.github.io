<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding and Improving Length Generalization in Recurrent Models | Goomba Lab </title> <meta name="author" content="Goomba AI Lab"> <meta name="description" content="Homepage of the Goomba AI Lab @ CMU MLD. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/goomba_light.png?68e59a389531e710f3507b5f12827027"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://goombalab.github.io/blog/2025/improving-length-generalization/"> <script src="/assets/js/theme.js?daf0da4e15ae2df6b4045ab97d680f8d"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Understanding and Improving Length Generalization in Recurrent Models",
            "description": "",
            "published": "July 06, 2025",
            "authors": [
              
              {
                "author": "Ricardo Buitrago Ruiz",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "CMU, Cartesia AI",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Albert Gu",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "CMU, Cartesia AI",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Goomba Lab <img src="/assets/img/goomba_transparent.png" width="30" height="30"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Understanding and Improving Length Generalization in Recurrent Models</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#existing-recurrent-models-still-fall-short">Existing Recurrent Models Still Fall Short</a> </div> <div> <a href="#why-do-recurrent-models-fail-to-length-generalize-the-unexplored-states-hypothesis">Why Do Recurrent Models Fail to Length Generalize? The Unexplored States Hypothesis</a> </div> <div> <a href="#interventions-to-enable-length-generalization">Interventions to Enable Length Generalization</a> </div> <div> <a href="#performance-on-long-context-tasks">Performance on Long Context Tasks</a> </div> <div> <a href="#a-deeper-look-into-how-recurrent-models-process-context">A Deeper Look into How Recurrent Models Process Context</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <div> <p>[<a href="https://arxiv.org/abs/2507.02782" rel="external nofollow noopener" target="_blank">Paper</a>]</p> <h2 id="existing-recurrent-models-still-fall-short">Existing Recurrent Models Still Fall Short</h2> <div style="text-align: justify; margin-bottom: 1em;"> Linear recurrent models such as Mamba <d-cite key="mamba"></d-cite><d-cite key="mamba2"></d-cite> and linear attention <d-cite key="LA_katharopoulos2020transformers"></d-cite><d-cite key="RQKV"></d-cite><d-cite key="gated_linear_attention_yang2024gla"></d-cite><d-cite key="delta_net"></d-cite> possess <strong>a remarkable feature: they can process extremely long sequences</strong>, which is key for applications that require long context reasoning (like summarizing long texts or agents with long term memory). Indeed, this is their key advantage over their main competitor, the Transformers <d-cite key="attention_is_all_you_need"></d-cite>, which are bottlenecked by their finite context window and quadratic complexity over the sequence length. </div> <div style="text-align: justify; margin-bottom: 1em;"> Previously, the issue with recurrent models was their performance: on short sequences they were less capable than Transformers. But recent architecture breakthroughs have improved the performance of recurrent models and brought them on par with Transformers, to the point that they are currently used in several industry applications like audio modeling <d-cite key="goel2024sonic"></d-cite> or code completion <d-cite key="mistral2024codestral"></d-cite>. However, several recent works have found out that <em>recurrent models still fall short</em>: they might have comparable performance to Transformers, but in many cases <strong>they perform very poorly on long sequences.</strong> </div> <div style="text-align: justify; margin-bottom: 1em;"> Indeed, we show the performance of the official Mamba-2 checkpoints <d-cite key="mamba2"></d-cite> as a function of the sequence position $t$ (using perplexity, the lower the better). It can be seen that for positions $t$ beyond the training context $T=2048$, these models become virtually useless: they fail to <em>length generalize</em>. </div> <div style="max-width: 500px; margin: 0 auto; text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/mamba2_poswise_reduced2-480.webp 480w,/assets/img/2025-07-06-length-generalization/mamba2_poswise_reduced2-800.webp 800w,/assets/img/2025-07-06-length-generalization/mamba2_poswise_reduced2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/mamba2_poswise_reduced2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div style="text-align: justify; margin-bottom: 1em;"> This is an issue: existing recurrent models have low performance on long sequences, and are not much more efficient than Transformers in shorter sequences; so they seem to be falling short on both sides. </div> <div style="text-align: justify; margin-bottom: 1em;"> Does this mean that recurrent models are useless? Not at all! In our work, we show that <strong>length generalization is easily achievable in many recurrent models through simple training interventions</strong>. Therefore, recurrent models possess an <em>unrealised potential</em> (it is really easy to make them better!) rather than a <em>fundamental limitation</em>. </div> <h2 id="why-do-recurrent-models-fail-to-length-generalize-the-unexplored-states-hypothesis">Why Do Recurrent Models Fail to Length Generalize? The <em>Unexplored States Hypothesis</em> </h2> <div style="text-align: justify; margin-bottom: 1em;"> For an input sequence with $t$ elements $(x_1, x_2, ..., x_{t-1}, x_t)$, recurrent models compress the input context $(x_1, x_2, ..., x_{t-1})$ into a fixed-size <em>recurrent state</em> $h_{t-1}$. At time $t=0$, the state is initialized with some value $h_{-1}$, and then it is updated at each $t$ with an update function $f$: </div> <div style="text-align: center;"> $ h_t = f(h_{t-1}, x_t) $ </div> <div style="text-align: justify; margin-bottom: 1em;"> Similarly, the output at time $t$ only depends on the state $h_t$ and the current input $x_t$, i.e. for some other function $g$ the output $y_t$ can be written as </div> <div style="text-align: center;"> $y_t = g(h_t, x_t)$ </div> <div style="text-align: justify; margin-bottom: 1em;"> The functions $f$ and $g$ do not depend on the position $t$, so in theory recurrent models can naturally process any sequence length. But then, how can it be that they fail when $t$ is large? </div> <div style="text-align: justify; margin-bottom: 1em;"> In our work we show that <strong>the distribution of the state $h_t$ changes over time</strong>. Therefore, even if $g$ and $f$ work correctly up to some $T$, other $h_t$ with $t&gt;T$ might be significantly different, and thus the model fails to produce the correct output. Indeed, in the following figure we show how the norm of the state of Mamba-2 <d-cite key="mamba2"></d-cite> increases significantly over time: </div> <div style="max-width: 400px; margin: 0 auto; text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/statemetrics_base-480.webp 480w,/assets/img/2025-07-06-length-generalization/statemetrics_base-800.webp 800w,/assets/img/2025-07-06-length-generalization/statemetrics_base-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/statemetrics_base.png" width="0.1" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div style="text-align: justify; margin-bottom: 1em;"> This explains why recurrent models fail to length generalize: when processing sequences longer than those seen during training, they encounter states $h_t$ that have not been explored during training, and thus they have not learnt to process them. Based on this insight, we propose the <strong>unexplored states hypothesis</strong> to explain the failure to length generalize: </div> <blockquote> <h4 id="unexplored-states-hypothesis">Unexplored States Hypothesis</h4> <p>Recurrent models fail to length generalize when they are trained only on a <strong>subset of all attainable state distributions</strong> – i.e. on a subset of the states that would be attained if the state recurrence was rolled out indefinitely.<br> <br> When trained for long enough, the model <strong>overfits to this subset</strong> and performs poorly on long sequences because it <strong>encounters unexplored state distributions</strong>.</p> </blockquote> <h2 id="interventions-to-enable-length-generalization">Interventions to Enable Length Generalization</h2> <div style="text-align: justify; margin-bottom: 1em;"> The unexplored states hypothesis indicates that length generalization can be achieved not by changing the architecture or its mechanisms, but by training the model on a more diverse set of state distributions—in particular, on the distributions that arise when rolling out the state recurrence on long sequences. To do so, we could directly train the model on longer sequences, but this might not always be possible due to GPU memory constraints or due to lack of sufficiently long training sequences. </div> <blockquote class="block-tip"> <h4 id="the-recipe-to-achieve-length-generalization-interventions-on-the-initial-state">The recipe to achieve length generalization: interventions on the initial state</h4> <div style="text-align: justify; margin-bottom: 1em;"> Most modern architectures assume a zero initial state ($h_{-1}=0$). In our work, we consider four simple interventions on the <strong>initial state</strong> $h_{-1}$, which increase the diversity of states that the model explores during training without the need of training on longer sequences.</div> </blockquote> <div style="text-align: justify; margin-bottom: 0.5em;"> The four training interventions can be seen as sampling the initial state $h_{-1}$ from four different distributions that progressively get closer to the distribution of attainable states: </div> <div style="text-align: justify; margin-bottom: 0.5em;"> 1. <strong>Random Noise</strong>: The state is initialized with an IID Gaussian with zero mean and a constant standard deviation (using the same mean / standard deviation for all layers and heads). </div> <div style="text-align: justify; margin-bottom: 0.5em;"> 2. <strong>Fitted Noise</strong>: During training, we record the mean and standard deviation of the final states of the sequences across all layers and heads. Then, we initialize the state with an IID Gaussian distribution with mean and standard deviation fitted to the ones seen during training (using a different mean / standard deviation for each layer and head). </div> <div style="text-align: justify; margin-bottom: 0.5em;"> 3. <strong>State Passing (SP)</strong><sup id="fnref1"><a href="#fn1">1</a></sup>: We use the final state of a previous (unrelated) sequence as the initial state. These states are obtained by rolling the state recurrence on a given sequence (similar to what happens in validation when processing long sequences), and thus this intervention samples <em>attainable</em> states. </div> <div style="text-align: justify; margin-bottom: 0.5em;"> 4. <strong>Truncated Backpropagation Through Time (TBTT)</strong> <d-cite key="TBTT_1990"></d-cite> <d-cite key="TBTT_sutskever"></d-cite>: In this case, we split a long sequence into smaller chunks, and use the final state of each chunk as the initial state of the next one. This is equivalent to processing the whole sequence, yet stopping the gradient propagation between chunks. </div> <details><summary>Difference between SP and TBTT</summary> <p>For simplicity, we implement SP by using the final state of the previous batch of sequences as the initial state of the new one. Thus, in practice the only difference between SP and TBTT is that TBTT requires carefully setting up the dataloader so that the sequences of the previous batch correspond to the prior parts of the sequences in the new batch.</p> </details> <div style="text-align: justify; margin-bottom: 1em;"> The following figures show the results of post-training the official Mamba-2 models for 100 steps (~0.02% of pre-training budget) with each intervention: </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/interventions_2-480.webp 480w,/assets/img/2025-07-06-length-generalization/interventions_2-800.webp 800w,/assets/img/2025-07-06-length-generalization/interventions_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/interventions_2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/interventions_1-480.webp 480w,/assets/img/2025-07-06-length-generalization/interventions_1-800.webp 800w,/assets/img/2025-07-06-length-generalization/interventions_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/interventions_1.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="takeaway-1-sp-and-tbtt-enable-length-generalization">Takeaway #1: SP and TBTT enable length generalization</h3> <p>State Passing and TBTT – which are the interventions that are closer to realistic states – allow length generalization in sequences much longer than those seen during training. Thus:</p> <blockquote class="block-tip"> <h4 id="takeaway">Takeaway</h4> <p>Length generalization is expected to be <strong>readily achievable in recurrent models</strong> through <strong>simple training interventions</strong>.</p> </blockquote> <p>Note that our results were achieved <em>with only ~0.02% of the original pre-training budget</em>!</p> <h3 id="takeaway-2-properties-of-the-state-of-recurrent-models">Takeaway #2: Properties of the state of recurrent models</h3> <blockquote class="block-tip"> <h4 id="takeaway-1">Takeaway</h4> <p>We can infer properties of the <strong>distribution of the state</strong> of recurrent models by looking at the <strong>performance of the interventions</strong>.</p> </blockquote> <p>The Random Noise intervention fails to length generalize in the 370m, whereas Fitted Noise works. This suggests that for the 370m model the distribution of attainable states cannot be approximated with a Gaussian with fixed variance, but it can be approximated with an IID Gaussian with fitted variance in each layer and head of the state. However, the Fitted Noise intervention fails to achieve length generalization in the 1.3b model, indicating that the state of large models probably has complex dependency relationships among its elements and thus cannot be approximated with IID values.</p> <div style="text-align: justify; margin-bottom: 1em;"> Additionally, the interventions also fix the increasing state norm behavior we showed before, by making the model output states with similar norm at all timesteps: </div> <div style="max-width: 400px; margin: 0 auto; text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/statemetrics_full-480.webp 480w,/assets/img/2025-07-06-length-generalization/statemetrics_full-800.webp 800w,/assets/img/2025-07-06-length-generalization/statemetrics_full-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/statemetrics_full.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <details><summary>SP in prior works</summary> <p id="fn1"> <sup>1</sup> Prior works have used the State Passing technique <d-cite key="longssm-wang2024longssmlengthextensionstatespace"></d-cite><d-cite key="end_to_end_bansal2022end"></d-cite>, yet it was applied to different recurrent architectures (e.g. time-invariant ones) or to tasks different to text modeling. To the best of our knowledge, we are the first to show that this technique used as a training intervention can greatly improve the length generalization of several recurrent models, and that it is as effective as TBTT in text modeling. <a href="#fnref1">↩</a> </p> </details> <h2 id="performance-on-long-context-tasks">Performance on Long Context Tasks</h2> <div style="text-align: justify; margin-bottom: 1em;"> We have seen that the interventions enable length <em>robustness</em> (i.e. not having decreased peformance after the training context $T$), but it is not clear whether they enable length <em>generalization</em> (i.e. solving tasks that require exploiting relationships between tokens that are separated by more than $T$ positions). One may wonder whether the interventions enable length robustness by simply preventing the model from reasoning beyond the training context length—similar to sliding window attention, which can't reason over tokens separated by more than the sliding window—in which case the models would have constant performance for all evaluation contexts $t &gt; T$, but could not solve tasks that require long context reasoning. In our work we show that <strong>the interventions do enable length generalization</strong> by showing results on three long context tasks. </div> <div style="text-align: justify; margin-bottom: 1em;"> <strong>BABILong</strong><d-cite key="babilong"></d-cite>. BABILong is a challenging benchmark which tests both the common sense understanding of a model as well as its ability to capture long range dependencies in text. In the figure below it can be observed that <strong>State Passing enhances the length generalization of the model in both the few-shot and finetuned settings</strong> (we recall that the model is trained and finetuned on sequences of length 2048). Therefore, State Passing is not only useful in fixing the diverging perplexity of established language models, but also in enhancing their ability to solve long context reasoning tasks. </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/babilong-480.webp 480w,/assets/img/2025-07-06-length-generalization/babilong-800.webp 800w,/assets/img/2025-07-06-length-generalization/babilong-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/babilong.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div style="text-align: justify; margin-bottom: 1em;"> <strong>Passkey retrieval</strong><d-cite key="landmark_attention_mohtashami2023randomaccess"></d-cite>. The passkey retrieval task requires the model to retrieve a 5-digit passkey inserted at a given depth of a long context. In the figure below we show the performance of the Mamba-2 370m and 780m official checkpoints in three settings: zero shot, regular finetuning, and finetuning with fitted noise (the finetuning is done for 1000 steps, $\sim0.2\%$ of pretraining buget). The models finetuned with fitted noise are capable of exploiting relationships between tokens that are much more than 2048 positions apart (the training context length). In particular, <strong>the 780m model can solve the passkey perfectly for sequences of length 256k</strong>. </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/passkey-480.webp 480w,/assets/img/2025-07-06-length-generalization/passkey-800.webp 800w,/assets/img/2025-07-06-length-generalization/passkey-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/passkey.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div style="text-align: justify; margin-bottom: 1em;"> <strong>Synthetic Copying</strong><d-cite key="transformers-better-copying-pmlr-v235-jelassi24a"></d-cite>. The synthetic copying task consists in copying an arbitrary sequence of tokens. In the table below we show that using State Passing during training greatly improves the validation performance in sequences more than three times longer. Thus, <strong>state passing helps the model length generalize, solving long context tasks that are harder than those seen during training</strong>. </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/synthetic_copying-480.webp 480w,/assets/img/2025-07-06-length-generalization/synthetic_copying-800.webp 800w,/assets/img/2025-07-06-length-generalization/synthetic_copying-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/synthetic_copying.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="a-deeper-look-into-how-recurrent-models-process-context">A Deeper Look into How Recurrent Models Process Context</h2> <div style="text-align: justify; margin-bottom: 1em;"> We have shown that the interventions on the initial state enable length robustness and allow solving long context tasks. On top of these findings, we now present a metric that sheds light on how sequence models process their context. </div> <div style="text-align: justify; margin-bottom: 1em;"> Ideally, in the case of text modeling we would like the model to pay attention to the recent context, and not focus too much on tokens that are too far away. But how can we quantify this behavior? We introduce <strong>Effective Remembrace</strong> to measure <strong>how much an autoregressive model is "effectively" remembering previous tokens</strong>. Denote by $q(\cdot \| \text{context})$ the probabilities that an autoregressive sequential model outputs for the next token given a context. Then, we define: </div> <div style="text-align: center;"> $ \text{EffRem}_T(t) = d(q(\cdot | x[0:T],q(\cdot | x[t:T])) $ </div> <div style="text-align: justify; margin-bottom: 1em;"> Where \( d(p,\bar{p}) \) is a distance between probability distributions (e.g., Total Variation). \(\text{EffRem}_T(t)\) roughly measures how much the model "effectively remembers" the tokens \( x[0:t-1] \) at time \( T \). If \( \text{EffRem}_T(t) = 0 \), this means that the predictions using \( x[t:T] \) and using \( x[0:T] \) are the same, meaning that <strong>the model does not "effectively remember" any of the past tokens \( x[0:t-1] \)</strong>. Conversely, if \( \text{EffRem}_T(t) \) is high, <strong>the model is substantially influenced by the tokens \( x[0:t-1] \)</strong>, since removing them from the context changes the prediction significantly. </div> <div style="text-align: justify; margin-bottom: 1em;"> The following figure shows $\text{EffRem}_T(t)$ for varying $t$ and $T=8192$ (four times the training context) for two Mamba-2 models: </div> <div style="max-width: 500px; margin: 0 auto; text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-07-06-length-generalization/mamba2-effrem-reduced-480.webp 480w,/assets/img/2025-07-06-length-generalization/mamba2-effrem-reduced-800.webp 800w,/assets/img/2025-07-06-length-generalization/mamba2-effrem-reduced-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/2025-07-06-length-generalization/mamba2-effrem-reduced.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h3 id="state-passing-fixes-effective-remembrance">State Passing fixes Effective Remembrance</h3> <p>Models that fail to length generalize have very high $\text{EffRem}_T(t)$ for small $t$, meaning that the models are disproportionately impacted by early elements of the sequence.</p> <blockquote class="block-tip"> <h4 id="intuition">Intuition</h4> <p>We hypothesize that when a model is always trained with a zero initial state, it uses the <strong>first few tokens it sees</strong> to rapidly differentiate the state, which in turn causes <strong>overfitting to these tokens</strong>.</p> </blockquote> <p>This effect is fixed with State Passing, showing that this intervention helps the models process the context in the intended way.</p> <h2 id="conclusion">Conclusion</h2> <div style="text-align: justify; margin-bottom: 1em;"> We have shown that <strong>length generalization is expected to be achievable in recurrent models</strong> through simple training interventions, without the need of changing the architecture nor the internal mechanisms of the model. Moreover, these interventions <strong>improve their performance on long context reasoning tasks</strong>, suggesting that existing recurrent models are not realising their full potential and can be easily improved. </div> <div style="text-align: justify; margin-bottom: 1em;"> Secondly, we believe that this work has significant implications for architecture research. For example, it has become very popular for modern recurrent architecture works to compare out-of-length extrapolation abilities <d-cite key="rwkv-v6-peng2024eaglefinchrwkvmatrixvalued"></d-cite><d-cite key="gated_delta_net_yang2024gateddeltanetworksimproving"></d-cite><d-cite key="beck2024xlstm"></d-cite>. In our work we show that <strong>simple training interventions substantially improve length generalization across several recurrent architectures</strong>, and thus research can focus mostly on the in-length performance (or if directly studying length generalization, it would be important to account for these interventions). </div> <div style="text-align: justify; margin-bottom: 1em;"> Lastly, <strong>we have proposed Effective Remembrance as a tool to understand how any autoregressive sequence model processes its context</strong>, thus making it easy to quantify how much models are "effectively remembering" parts of the context. </div> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/ricardo.bib"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Goomba AI Lab. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cloud.umami.is/script.js" data-website-id="340bca3c-b84e-462f-98dd-f4f4629b9751"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>